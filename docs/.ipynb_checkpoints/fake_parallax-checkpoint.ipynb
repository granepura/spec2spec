{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52043ae5-93c4-455d-9f3b-294ad345c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "import matplotlib\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 14\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as snb\n",
    "import copy\n",
    "import sys\n",
    "sys.path.append('/home/jdli/TransSpectra/')\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "from astropy.table import Table\n",
    "\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer import TransformerReg\n",
    "# from train_ap14 import ASPCAP\n",
    "from data import AP_fakeprlx\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636829a8-967d-4160-935a-90fe91667795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap_prlx_trsfm_221018.pt\t\t      ap_prlx_trsfm_error221023B_nnNorm.pt\n",
      "ap_prlx_trsfm_221019.pt\t\t      trsfm_221025A.pt\n",
      "ap_prlx_trsfm_error221020.pt\t      trsfm_221025B.pt\n",
      "ap_prlx_trsfm_error221021A.pt\t      trsfm_221028_fakeA.pt\n",
      "ap_prlx_trsfm_error221021B.pt\t      trsfm_221029A.pt\n",
      "ap_prlx_trsfm_error221023A_nnNorm.pt\n"
     ]
    }
   ],
   "source": [
    "! ls /data/jdli/sdss/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2708667-e3be-4b19-9065-3864ba5444b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 3000\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/data/jdli/sdss/\"\n",
    "tr_file = \"hogg19_spec_nnnorm_tr.npy\"\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "TOTAL_NUM = 6000\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "apdata = AP_fakeprlx(data_dir+tr_file, \n",
    "                     total_num=6000, part_train=True, device=device)\n",
    "\n",
    "A_size = int(0.5*(len(apdata)))\n",
    "B_size = len(apdata) - A_size\n",
    "\n",
    "A_dataset, B_dataset = torch.utils.data.random_split(apdata, [A_size, B_size], \n",
    "                                                     generator=torch.Generator().manual_seed(42))\n",
    "print(len(A_dataset), len(B_dataset),)\n",
    "\n",
    "A_loader = DataLoader(A_dataset, batch_size=BATCH_SIZE, )\n",
    "B_loader = DataLoader(B_dataset, batch_size=BATCH_SIZE, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91dc36a-b130-4130-8241-94f4ea63e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model parameters\n",
    "dim_val = 64 # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
    "n_heads = 4 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
    "n_decoder_layers = 2 # Number of times the decoder layer is stacked in the decoder\n",
    "n_encoder_layers = 2 # Number of times the encoder layer is stacked in the encoder\n",
    "input_size = 1 # The number of input variables. 1 if univariate forecasting.\n",
    "enc_seq_len = 7514 # length of input given to encoder. Can have any integer value.\n",
    "dec_seq_len = 2 # length of input given to decoder. Can have any integer value.\n",
    "output_sequence_length = 2 # Length of the target sequence, i.e. how many time steps should your forecast\n",
    "max_seq_len = 7514 # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
    "model = TransformerReg(dim_val=dim_val, input_size=input_size, \n",
    "                       batch_first=True, dec_seq_len=dec_seq_len, \n",
    "                       out_seq_len=output_sequence_length, n_decoder_layers=n_decoder_layers,\n",
    "                       n_encoder_layers=n_encoder_layers, n_heads=n_heads,\n",
    "                       max_seq_len=max_seq_len,\n",
    "                       ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdecaec-ad2d-4465-84e1-d0cfa7a1d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"model/trsfm_221028_fakeA.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(data_dir+model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83adec4-38bf-448d-8720-93965bf85f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████████████████████▊                                 | 394/750 [00:38<00:34, 10.21it/s]"
     ]
    }
   ],
   "source": [
    "def predict(data_loader, model):\n",
    "    \n",
    "    out_lst, y_lst = np.array([]), np.array([])\n",
    "    id_lst = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            output = model(data['x'], data['y'])\n",
    "            out_lst = np.append(out_lst, output.cpu().numpy())\n",
    "            y_lst   = np.append(y_lst, data['y'].cpu().numpy())\n",
    "            # id_lst = np.append(id_lst, data['id'])\n",
    "            del output, data\n",
    "\n",
    "    out_lst, y_lst = np.array(out_lst).reshape(-1,2), np.array(y_lst).reshape(-1,2)\n",
    "    return out_lst, y_lst\n",
    "\n",
    "\n",
    "out_lst_B, y_lst_B = predict(B_loader, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f63339-5d79-42a5-9732-bf56083ef70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_compare(out_lst, y_lst, errorbar=True):\n",
    "    xx = np.linspace(-0.5, 1.5)\n",
    "    \n",
    "    norm_res = y_lst[:,0]-out_lst[:,0]\n",
    "    print(\"residuals mean : %.2f, scatter : %.2f \"%(np.nanmedian(norm_res), np.nanstd(norm_res)))\n",
    "    print(\"residuals/y mean : %.2f percent\"%(100./np.nanmedian(y_lst[:,0]/norm_res)))\n",
    "\n",
    "    varpi_bin = np.linspace(-0.3, 1.3, 10)\n",
    "    e_varpi = []\n",
    "\n",
    "    for i in range(len(varpi_bin)-1):\n",
    "        ind = (y_lst[:,0]>varpi_bin[i]) & (y_lst[:,0]<=varpi_bin[i+1])\n",
    "\n",
    "        e_varpi.append(np.median(y_lst[:,1][ind]))\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, figsize=(6,6),  sharex=True)\n",
    "    ax.plot(xx, xx, ls=':', lw=3, c='k', zorder=5)\n",
    "    \n",
    "    if errorbar:\n",
    "        ax.errorbar(y_lst[:,0], out_lst[:,0],\n",
    "                      xerr=y_lst[:,1], yerr=np.abs(out_lst[:,1]),\n",
    "                     capthick=0.01, fmt='.', capsize=0, c='royalblue', alpha=0.1, zorder=4)\n",
    "    else:\n",
    "        ax.scatter(y_lst[:,0], out_lst[:,0], s=1,\n",
    "                   marker='.', c='royalblue', alpha=0.5, zorder=4)\n",
    "\n",
    "    ax.set_xlim([-0.3, 1.2]);\n",
    "    ax.set_ylim([-0.3, 1.2]);\n",
    "    ax.set_ylabel(r\"Trans. $\\varpi$ (mas)\");\n",
    "    ax.annotate(\"scatter = %.4f mas\"%(np.nanstd(norm_res)), \n",
    "                (0.58, 0.35), xycoords=\"figure fraction\",zorder=3)\n",
    "    ax.annotate(\"  bias   = %.4f mas\"%(np.nanmean(norm_res)), \n",
    "                (0.58, 0.40), xycoords=\"figure fraction\",zorder=3)\n",
    "    \n",
    "    divider = make_axes_locatable(ax)\n",
    "    ax2 = divider.append_axes(\"bottom\", size=\"33%\", pad=0)\n",
    "\n",
    "    norm_res = y_lst[:,0]-out_lst[:,0]\n",
    "    ax.figure.add_axes(ax2)\n",
    "    ax2.scatter(y_lst[:,0], norm_res, color=\"crimson\", s=1, zorder=5)\n",
    "    ax2.axhline(y=0, c='k', zorder=4, lw=3, ls=\":\")\n",
    "    ax2.set_xlabel(r\"Gaia $\\varpi$ (mas)\");\n",
    "    ax2.set_ylim([-0.42, 0.42]);\n",
    "    ax2.set_xlim([-0.3, 1.2]);\n",
    "    ax2.set_ylabel(r'$\\Delta \\varpi$ (mas)');\n",
    "\n",
    "    for i in range(len(varpi_bin)-1):\n",
    "        ax2.axhspan(-e_varpi[i], e_varpi[i], varpi_bin[i], varpi_bin[i+1],\n",
    "                    facecolor='grey', alpha=0.6, zorder=6)\n",
    "    ax.set_xticks([]);\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887530d-1a65-43a6-8163-283597914651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = draw_compare(out_lst_B, y_lst_B)\n",
    "ax.set_title(\"dataset A\");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
