{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efb13241-1a7e-40fc-b276-cb96aafe9979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "def smape_loss(y_pred, target):\n",
    "    loss = 2 * (y_pred - target).abs() / (y_pred.abs() + target.abs() + 1e-8)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def gen_trg_mask(length, device):\n",
    "    mask = torch.tril(torch.ones(length, length, device=device)) == 1\n",
    "\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "class Spec2label(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_encoder_inputs,\n",
    "        n_outputs,\n",
    "        channels=512,\n",
    "        dropout=0.2,\n",
    "        lr=1e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.channels = channels\n",
    "        self.n_outputs = n_outputs\n",
    "        self.lr = lr\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.input_pos_embedding = torch.nn.Embedding(1024, embedding_dim=channels)\n",
    "        self.target_pos_embedding = torch.nn.Embedding(1024, embedding_dim=channels)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=channels,\n",
    "            nhead=8,\n",
    "            dropout=self.dropout,\n",
    "            dim_feedforward=4*channels,\n",
    "        )\n",
    "        # decoder_layer = nn.TransformerDecoderLayer(\n",
    "        #     d_model=channels,\n",
    "        #     nhead=8,\n",
    "        #     dropout=self.dropout,\n",
    "        #     dim_feedforward=4 * channels,\n",
    "        # )\n",
    "\n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=8)\n",
    "        # self.decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=8)\n",
    "\n",
    "        self.input_projection = Linear(n_encoder_inputs, channels)\n",
    "        # self.output_projection = Linear(n_decoder_inputs, channels)\n",
    "\n",
    "        # self.linear = Linear(channels, 2)\n",
    "        self.fc1 = Linear(channels, 64)\n",
    "        self.fc2 = Linear(64, n_outputs)\n",
    "        self.do = nn.Dropout(p=self.dropout)\n",
    "\n",
    "    def encode_src(self, src):\n",
    "        src_start = self.input_projection(src).permute(1, 0, 2)\n",
    "\n",
    "        in_sequence_len, batch_size = src_start.size(0), src_start.size(1)\n",
    "        pos_encoder = (\n",
    "            torch.arange(0, in_sequence_len, device=src.device)\n",
    "            .unsqueeze(0)\n",
    "            .repeat(batch_size, 1)\n",
    "        )\n",
    "        \n",
    "        pos_encoder = self.input_pos_embedding(pos_encoder).permute(1, 0, 2)\n",
    "\n",
    "        src = src_start + pos_encoder\n",
    "        src = self.encoder(src) + src_start\n",
    "\n",
    "        return src\n",
    "\n",
    "    def forward(self, x):\n",
    "        src = x\n",
    "        \n",
    "        src = self.encode_src(src) # (1, bs, 512)\n",
    "        src = F.relu(src) # (1, bs, 512)\n",
    "        \n",
    "        src = src.permute(1, 0, 2) #(bs, 1, 512)\n",
    "        src = src.view(-1, self.channels) # (bs, 512)\n",
    "\n",
    "        src = self.fc1(src) # (bs, 64)\n",
    "        src = F.relu(src)\n",
    "        tgt = self.fc2(src) # (bs, 2)\n",
    "        # out = self.decode_trg(trg=trg, memory=src)\n",
    "        return tgt\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        src, trg_out = batch['x'], batch['y']\n",
    "\n",
    "        y_hat = self((src))\n",
    "\n",
    "        y_hat = y_hat.view(-1)\n",
    "        y = trg_out.view(-1)\n",
    "\n",
    "        loss = smape_loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        src, trg_out = batch['x'], batch['y']\n",
    "\n",
    "        y_hat = self((src))\n",
    "\n",
    "        y_hat = y_hat.view(-1)\n",
    "        y = trg_out.view(-1)\n",
    "\n",
    "        loss = smape_loss(y_hat, y)\n",
    "        self.log(\"valid_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        src, trg_out = batch['x'], batch['y']\n",
    "\n",
    "        y_hat = self((src))\n",
    "\n",
    "        y_hat = y_hat.view(-1)\n",
    "        y = trg_out.view(-1)\n",
    "\n",
    "        loss = smape_loss(y_hat, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, patience=10, factor=0.1\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": scheduler,\n",
    "            \"monitor\": \"valid_loss\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a366f1de-2dbe-4d81-9535-96fdc2427ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "source = torch.rand(size=(5, 1, 343))\n",
    "target_in = torch.rand(size=(5, 1, 343))\n",
    "target_out = torch.rand(size=(5, 1, 2))\n",
    "\n",
    "# source = torch.rand(size=(32, 16, 9))\n",
    "# target_in = torch.rand(size=(32, 16, 8))\n",
    "# target_out = torch.rand(size=(32, 16, 1))\n",
    "ts = Spec2label(n_encoder_inputs=343, n_outputs=2)\n",
    "pred = ts((source))\n",
    "\n",
    "print(pred.size())\n",
    "\n",
    "# ts.training_step((source, target_in, target_out), batch_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7382c873-6bea-4f8d-996e-1d1ace89fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450 450 100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jdli/TransSpectra/\")\n",
    "from data import GaiaXPlabel_v2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "data_dir = \"/data/jdli/gaia/\"\n",
    "tr_file = \"ap17_xp.npy\"\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "gdata  = GaiaXPlabel_v2(data_dir+tr_file, total_num=1000, part_train=True, device=device)\n",
    "\n",
    "val_size = int(0.1*len(gdata))\n",
    "A_size = int(0.5*(len(gdata)-val_size))\n",
    "B_size = len(gdata) - A_size - val_size\n",
    "\n",
    "A_dataset, B_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    gdata, [A_size, B_size, val_size], \n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "print(len(A_dataset), len(B_dataset), len(val_dataset))\n",
    "\n",
    "A_loader = DataLoader(A_dataset, batch_size=BATCH_SIZE)\n",
    "B_loader = DataLoader(B_dataset, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6d0e75c5-ee16-44b6-b5ea-6bfb4a50e2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_loader, val_loader,\n",
    "    output_json_path: str,\n",
    "    log_dir: str = \"ts_logs\",\n",
    "    model_dir: str = \"ts_models\",\n",
    "    batch_size: int = 8,\n",
    "    epochs: int = 2000,\n",
    "    horizon_size: int = 30,\n",
    "):\n",
    "\n",
    "    model = Spec2label(\n",
    "        n_encoder_inputs=343,\n",
    "        n_outputs=2,\n",
    "        lr=1e-5,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=log_dir,\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"valid_loss\",\n",
    "        mode=\"min\",\n",
    "        dirpath=model_dir,\n",
    "        filename=\"ts\",\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=epochs,\n",
    "        accelerator='gpu', devices=1,\n",
    "        logger=logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    result_val = trainer.test(test_dataloaders=val_loader)\n",
    "\n",
    "    output_json = {\n",
    "        \"val_loss\": result_val[0][\"test_loss\"],\n",
    "        \"best_model_path\": checkpoint_callback.best_model_path,\n",
    "    }\n",
    "\n",
    "    if output_json_path is not None:\n",
    "        with open(output_json_path, \"w\") as f:\n",
    "            json.dump(output_json, f, indent=4)\n",
    "\n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ecf564-7c47-4bfe-9e0e-608eda94c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/jdli/anaconda3/envs/gaia/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True (cuda), used: True\n",
      "/data/jdli/anaconda3/envs/gaia/lib/python3.9/site-packages/pkg_resources/__init__.py:123: PkgResourcesDeprecationWarning: 1. is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name                 | Type               | Params\n",
      "------------------------------------------------------------\n",
      "0 | input_pos_embedding  | Embedding          | 524 K \n",
      "1 | target_pos_embedding | Embedding          | 524 K \n",
      "2 | encoder              | TransformerEncoder | 25.2 M\n",
      "3 | input_projection     | Linear             | 176 K \n",
      "4 | fc1                  | Linear             | 32.8 K\n",
      "5 | fc2                  | Linear             | 130   \n",
      "6 | do                   | Dropout            | 0     \n",
      "------------------------------------------------------------\n",
      "26.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.5 M    Total params\n",
      "105.907   Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 10\n",
    "\n",
    "train(\n",
    "    A_loader, val_loader,\n",
    "    output_json_path=\"/data/jdli/gaia/model/forcasting_1107A.json\",\n",
    "    log_dir=\"/data/jdli/gaia/model/forcasting_1107A.log\",\n",
    "    model_dir=\"/data/jdli/gaia/model/forcasting_1107A.pt\",\n",
    "    epochs=EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc77bfb-4a3d-47d7-83e3-afa692441cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
